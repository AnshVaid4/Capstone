{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-22T15:24:19.467938Z","iopub.execute_input":"2022-01-22T15:24:19.468663Z","iopub.status.idle":"2022-01-22T15:24:19.503414Z","shell.execute_reply.started":"2022-01-22T15:24:19.468535Z","shell.execute_reply":"2022-01-22T15:24:19.502688Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error,r2_score,mean_squared_error,accuracy_score,classification_report,confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\n#from sklearn.linear_model import LinearRegression,RANSACRegressor,Lasso,BayesianRidge,ElasticNet\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import dtale\n#import dtale.app as dtale_app\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom sklearn.svm import SVR\n#from sklearn.tree import DecisionTreeRegressor\n#from sklearn.neighbors import KNeighborsRegressor\n#from sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier#Bagging\nfrom sklearn.ensemble import BaggingClassifier #Bagging\nfrom sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier\n#from pandas_profiling import ProfileReport\nfrom xgboost import XGBClassifier\nfrom sklearn.tree import _tree\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:24:19.505033Z","iopub.execute_input":"2022-01-22T15:24:19.505433Z","iopub.status.idle":"2022-01-22T15:24:20.961221Z","shell.execute_reply.started":"2022-01-22T15:24:19.505399Z","shell.execute_reply":"2022-01-22T15:24:20.960162Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ids_datatypes = {\n    'Dst Port': np.int32,\n    'Protocol': np.int8,\n    'Flow Duration': np.int64,\n    'Tot Fwd Pkts': np.int16,\n    'Tot Bwd Pkts': np.int16,\n    'TotLen Fwd Pkts': np.int32,\n    'TotLen Bwd Pkts': np.int32,\n    'Fwd Pkt Len Max': np.int32,\n    'Fwd Pkt Len Min': np.int32,\n    'Fwd Pkt Len Mean': np.float64,\n    'Fwd Pkt Len Std': np.float64,\n    'Bwd Pkt Len Max': np.int16,\n    'Bwd Pkt Len Min': np.int16,\n    'Bwd Pkt Len Mean': np.float64,\n    'Bwd Pkt Len Std': np.float64,\n    'Flow Byts/s': np.float64,\n    'Flow Pkts/s': np.float64,\n    'Flow IAT Mean': np.float64,\n    'Flow IAT Std': np.float64,\n    'Flow IAT Max': np.int64,\n    'Flow IAT Min': np.int32,\n    'Fwd IAT Tot': np.int32,\n    'Fwd IAT Mean': np.float32,\n    'Fwd IAT Std': np.float64,\n    'Fwd IAT Max': np.int32, \n    'Fwd IAT Min': np.int32,\n    'Bwd IAT Tot': np.int32,\n    'Bwd IAT Mean': np.float64,\n    'Bwd IAT Std': np.float64,\n    'Bwd IAT Max': np.int64,\n    'Bwd IAT Min': np.int64,\n    'Fwd PSH Flags': np.int8,\n    'Bwd PSH Flags': np.int8,\n    'Fwd URG Flags': np.int8,\n    'Bwd URG Flags': np.int8,\n    'Fwd Header Len': np.int32,\n    'Bwd Header Len': np.int32,\n    'Fwd Pkts/s' : np.float64,\n    'Bwd Pkts/s': np.float64,\n    'Pkt Len Min': np.int16,\n    'Pkt Len Max': np.int32,\n    'Pkt Len Mean': np.float64,\n    'Pkt Len Std': np.float64,\n    'Pkt Len Var': np.float64,\n    'FIN Flag Cnt': np.int8,\n    'SYN Flag Cnt': np.int8,\n    'RST Flag Cnt': np.int8,\n    'PSH Flag Cnt': np.int8,\n    'ACK Flag Cnt': np.int8,\n    'URG Flag Cnt': np.int8,\n    'CWE Flag Count': np.int8,\n    'ECE Flag Cnt': np.int8,\n    'Pkt Size Avg': np.float32,\n    'Fwd Seg Size Avg': np.float32,\n    'Bwd Seg Size Avg': np.float32,\n    'Fwd Byts/b Avg': np.int8,\n    'Fwd Pkts/b Avg': np.int8,\n    'Fwd Blk Rate Avg': np.int8,\n    'Bwd Byts/b Avg': np.int8,\n    'Bwd Pkts/b Avg': np.int8,\n    'Bwd Blk Rate Avg': np.int8,\n    'Subflow Fwd Pkts': np.int16,\n    'Subflow Fwd Byts': np.int32,\n    'Subflow Bwd Pkts': np.int16,\n    'Subflow Bwd Byts': np.int32,\n    'Init Fwd Win Byts': np.int32, \n    'Init Bwd Win Byts': np.int32,\n    'Fwd Act Data Pkts': np.int16,\n    'Fwd Seg Size Min': np.int8,\n    'Active Mean': np.float64,\n    'Active Std': np.float64,\n    'Active Max': np.int32,\n    'Active Min': np.int32,\n    'Idle Mean': np.float64,\n    'Idle Std': np.float64,\n    'Idle Max': np.int64,\n    'Idle Min': np.int64,\n    'Label': object\n}\nused_cols = (ids_datatypes.keys())","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:24:20.962370Z","iopub.execute_input":"2022-01-22T15:24:20.962577Z","iopub.status.idle":"2022-01-22T15:24:20.979552Z","shell.execute_reply.started":"2022-01-22T15:24:20.962550Z","shell.execute_reply":"2022-01-22T15:24:20.978600Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"../input/ids-intrusion-csv/02-14-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\ndf2 = pd.read_csv(\"../input/ids-intrusion-csv/02-15-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\n#df3 = pd.read_csv(\"../input/ids-intrusion-csv/02-16-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\n#df4 = pd.read_csv(\"../input/ids-intrusion-csv/02-20-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\ndf5 = pd.read_csv(\"../input/ids-intrusion-csv/02-21-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\ndf6 = pd.read_csv(\"../input/ids-intrusion-csv/02-22-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\ndf7 = pd.read_csv(\"../input/ids-intrusion-csv/02-23-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\n#df8 = pd.read_csv(\"../input/ids-intrusion-csv/02-28-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\n#df9 = pd.read_csv(\"../input/ids-intrusion-csv/03-01-2018.csv\", dtype=ids_datatypes, usecols=used_cols)\ndf10 = pd.read_csv(\"../input/ids-intrusion-csv/03-02-2018.csv\", dtype=ids_datatypes, usecols=used_cols)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:24:20.981022Z","iopub.execute_input":"2022-01-22T15:24:20.982231Z","iopub.status.idle":"2022-01-22T15:25:28.007389Z","shell.execute_reply.started":"2022-01-22T15:24:20.982126Z","shell.execute_reply":"2022-01-22T15:25:28.006412Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"merge = [\n    df1, \n    df2,\n    df5,\n    df6, \n    df7, \n    df10\n]\ndf_ids = pd.concat(merge)\ndel df1\ndel df2\ndel df5\ndel df6\ndel df7\ndel df10\ndel merge\n#df_ids.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:25:28.009524Z","iopub.execute_input":"2022-01-22T15:25:28.009807Z","iopub.status.idle":"2022-01-22T15:25:29.682013Z","shell.execute_reply.started":"2022-01-22T15:25:28.009780Z","shell.execute_reply":"2022-01-22T15:25:29.680991Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"label_dict = {\n    'Benign': 1,\n    'FTP-BruteForce': 2,\n    'SSH-Bruteforce': 3,\n    'DDOS attack-HOIC': 4,\n    'Bot': 5,\n    'DoS attacks-GoldenEye' : 6,\n    'DoS attacks-Slowloris': 7,\n    'DDOS attack-LOIC-UDP': 8,\n    'Brute Force -Web': 9,\n    'Brute Force -XSS': 10,\n    'SQL Injection': 11\n}\ndf_ids['Label'] = [label_dict[item] for item in df_ids['Label']]\ndf_ids = df_ids.replace([np.inf, -np.inf], np.nan)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:25:29.683828Z","iopub.execute_input":"2022-01-22T15:25:29.684492Z","iopub.status.idle":"2022-01-22T15:25:36.466565Z","shell.execute_reply.started":"2022-01-22T15:25:29.684450Z","shell.execute_reply":"2022-01-22T15:25:36.465844Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"label_undict = {\n    1:'Benign',\n    2:'FTP-BruteForce',\n     3 :'SSH-Bruteforce',\n    4 :'DDOS attack-HOIC',\n     5:'Bot',\n     6:'DoS attacks-GoldenEye' ,\n     7:'DoS attacks-Slowloris',\n     8:'DDOS attack-LOIC-UDP',\n     9:'Brute Force -Web',\n     10:'Brute Force -XSS',\n     11:'SQL Injection'\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:25:36.467563Z","iopub.execute_input":"2022-01-22T15:25:36.468232Z","iopub.status.idle":"2022-01-22T15:25:36.474051Z","shell.execute_reply.started":"2022-01-22T15:25:36.468185Z","shell.execute_reply":"2022-01-22T15:25:36.472995Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def cleandata(df,ids=\"\",target=\"\"):\n    scale = MinMaxScaler()#scaler\n    #print(df)\n    cols=df.columns#name of columns\n    for label, content in df.items():#identifying category type features\n        if pd.api.types.is_string_dtype(content):\n            df[label] = content.astype(\"category\").cat.as_ordered()\n\n    for label, content in df.items():#handling missing data in Numeric type\n        if pd.api.types.is_numeric_dtype(content):\n             if pd.isnull(content).sum():\n                    # Fill missing numeric values with median since it's more robust than the mean\n                    #print(label)\n                    df[label] = content.fillna(content.median())  \n    rev=[]\n    Encoder=LabelEncoder()\n    for label, content in df.items():\n        # Check columns which *aren't* numeric\n         if not pd.api.types.is_numeric_dtype(content):\n                #encoding category type features into numeric format\n                rev.append(label)\n                df[label]=Encoder.fit_transform(df[label])\n    scaling=[]\n    for label,content in df.items():#scaling the data excluding Target\n        if (label!=ids and label not in rev ):\n            scaling.append(label)\n    if(len(target)>0):scaling.remove(target)\n    df[scaling]=scale.fit_transform(df[scaling])\n    #df[label]=scaled(df[label])\n    #print(df)\n    return df\n\nfor label, content in df_ids.items():#handling missing data in Numeric type\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            # Fill missing numeric values with median since it's more robust than the mean\n            #print(label)\n            df_ids[label] = content.fillna(content.median())\n","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:25:36.475377Z","iopub.execute_input":"2022-01-22T15:25:36.475638Z","iopub.status.idle":"2022-01-22T15:25:37.510810Z","shell.execute_reply.started":"2022-01-22T15:25:36.475612Z","shell.execute_reply":"2022-01-22T15:25:37.509553Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y = df_ids[['Label']]\nX = df_ids.drop('Label',axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.1)\ndel df_ids","metadata":{"execution":{"iopub.status.busy":"2022-01-22T15:25:37.512226Z","iopub.execute_input":"2022-01-22T15:25:37.512470Z","iopub.status.idle":"2022-01-22T15:25:46.565898Z","shell.execute_reply.started":"2022-01-22T15:25:37.512441Z","shell.execute_reply":"2022-01-22T15:25:46.564934Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def model_selection(X_train, X_test, y_train, y_test):#function to select optimum model\n    mod = {   \"Bernouli\":BernoulliNB(),\n              \"Perceptron\":Perceptron(),\n              #\"KNC\" :KNeighborsClassifier(n_neighbors=11),\n              \"Gausian\":GaussianNB(),\n              \"DTree\":DecisionTreeClassifier(max_depth=15),\n              \"Rforest\":RandomForestClassifier(max_depth=15),\n              \"ETree\":ExtraTreesClassifier(max_depth=15),\n              #\"Gradient\":GradientBoostingClassifier(n_estimators=500, max_depth=10, learning_rate=0.01),\n              \"Ada\":AdaBoostClassifier(),\n              #\"XGB\":XGBClassifier(),\n              \"Logistic\":LogisticRegression(max_iter=150)\n              }\n    Err={}\n    for key,value in mod.items():#mapping models with their accuracy score\n        mod[key].fit(X_train,y_train)\n        pred_test=mod[key].predict(X_test)\n        Err[key]=accuracy_score(y_test,pred_test)\n        print(f\"{key} : {Err[key]}\")\n\n    plt.xticks(rotation = 45) #ploting models with thier respective accuracy score\n    plt.bar(Err.keys(),Err.values(),align='center')\n    plt.show()\nmodel_selection(X_train, X_test, y_train, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Dtree = DecisionTreeClassifier(max_depth=15, random_state=1234)\nmodel = Dtree.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T16:08:51.712183Z","iopub.execute_input":"2022-01-22T16:08:51.712729Z","iopub.status.idle":"2022-01-22T16:14:18.970394Z","shell.execute_reply.started":"2022-01-22T16:08:51.712648Z","shell.execute_reply":"2022-01-22T16:14:18.969700Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"f = open(\"output.txt\", \"a\")\ndef tree_to_code(tree, feature_names):\n    \n    tree_ = tree.tree_\n    feature_name = [\n        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n        for i in tree_.feature\n    ]\n    feature_names = [f.replace(\" \", \"_\")[:-5] for f in feature_names]\n    print(\"def predict({}):\".format(\", \".join(feature_names)),file=f)\n\n    def recurse(node, depth):\n        indent = \"    \" * depth\n        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n            name = feature_name[node]\n            threshold = tree_.threshold[node]\n            print(\"{}if {} <= {}:\".format(indent, name, np.round(threshold,2)),file=f)\n            recurse(tree_.children_left[node], depth + 1)\n            print(\"{}else:  # if {} > {}\".format(indent, name, np.round(threshold,2)),file=f)\n            recurse(tree_.children_right[node], depth + 1)\n        else:\n            print(\"{}return {}\".format(indent, tree_.value[node]),file=f)\n\n    recurse(0, 1)\ntree_to_code(model,list(ids_datatypes.keys()))\nf.close()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T16:14:18.972144Z","iopub.execute_input":"2022-01-22T16:14:18.975414Z","iopub.status.idle":"2022-01-22T16:14:19.024622Z","shell.execute_reply.started":"2022-01-22T16:14:18.975356Z","shell.execute_reply":"2022-01-22T16:14:19.023680Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_rules(tree, feature_names, class_names):\n    tree_ = tree.tree_\n    feature_name = [\n        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n        for i in tree_.feature\n    ]\n\n    paths = []\n    path = []\n    \n    def recurse(node, path, paths):\n        \n        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n            name = feature_name[node]\n            threshold = tree_.threshold[node]\n            p1, p2 = list(path), list(path)\n            p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n            recurse(tree_.children_left[node], p1, paths)\n            p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n            recurse(tree_.children_right[node], p2, paths)\n        else:\n            path += [(tree_.value[node], tree_.n_node_samples[node])]\n            paths += [path]\n            \n    recurse(0, path, paths)\n\n    # sort by samples count\n    samples_count = [p[-1][1] for p in paths]\n    ii = list(np.argsort(samples_count))\n    paths = [paths[i] for i in reversed(ii)]\n    \n    rules = []\n    for path in paths:\n        rule = \"if \"\n        \n        for p in path[:-1]:\n            if rule != \"if \":\n                rule += \" and \"\n            rule += str(p)\n        rule += \" then \"\n        if class_names is None:\n            rule += \"response: \"+str(np.round(path[-1][0][0][0],3))\n        else:\n            classes = path[-1][0][0]\n            l = np.argmax(classes)\n            rule += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n        rule += f\" | based on {path[-1][1]:,} samples\"\n        rules += [rule]\n        \n    return rules\nrule=get_rules(model,list(ids_datatypes.keys()) , list(label_dict.keys()))\nf = open(\"output_human.txt\", \"a\")\nprint(rule,file=f)\nf.close()","metadata":{"execution":{"iopub.status.busy":"2022-01-22T16:14:19.025940Z","iopub.execute_input":"2022-01-22T16:14:19.026288Z","iopub.status.idle":"2022-01-22T16:14:19.058038Z","shell.execute_reply.started":"2022-01-22T16:14:19.026241Z","shell.execute_reply":"2022-01-22T16:14:19.057161Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('Dtree.pkl', 'wb') as f:\n    pickle.dump(model, f)\n#with open('Dtree.pkl', 'rb') as f:\n    #clf = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-01-22T16:14:19.059907Z","iopub.execute_input":"2022-01-22T16:14:19.060338Z","iopub.status.idle":"2022-01-22T16:14:19.075179Z","shell.execute_reply.started":"2022-01-22T16:14:19.060293Z","shell.execute_reply":"2022-01-22T16:14:19.074278Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}